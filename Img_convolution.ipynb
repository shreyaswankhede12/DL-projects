{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AI21BTECH11028 \n",
    "SHREYAS WANKHEDE \n",
    "ASSIGNMENT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1205,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torchvision import transforms,datasets\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from math import floor\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return (1/(1+np.exp(-1*x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the softmax function\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART 1: CONVOLUTION OPERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convolution function that takes image,kernel,stride.padding , no. of filters as arguments\n",
    "def convolution_op(input_img,filter,s,p,d,sigmoid):\n",
    "    # creating output array of necessary dimensions\n",
    "    out=np.empty((d,int(((input_img.shape[1]-filter.shape[1]+2*p)/s)+1),int(((input_img.shape[2]-filter.shape[2]+2*p)/s)+1)))\n",
    "    \n",
    "    #padding \n",
    "    new_inp_img=np.zeros((filter.shape[0],input_img.shape[1]+2*p,input_img.shape[2]+2*p))\n",
    "    for k in range(filter.shape[0]):\n",
    "     for i in range(p,input_img.shape[1]-p):\n",
    "       for j in range(p,input_img.shape[2]-p):\n",
    "           new_inp_img[k][i][j]=input_img[k][i-p][j-p]\n",
    "    \n",
    "    #convolution operation\n",
    "    \n",
    "    for k in range(d):  #iterating for no. of filters      \n",
    "      for i in range(0,new_inp_img.shape[1],s):  #moving along height\n",
    "        for j in range(0,new_inp_img.shape[2],s):  #moving along width\n",
    "           sum=0\n",
    "           if(i+filter.shape[1]>new_inp_img.shape[1] or j+filter.shape[2]>new_inp_img.shape[2]):\n",
    "              sum=0\n",
    "              break\n",
    "           else:\n",
    "              #summing up the results \n",
    "              new_sum=0\n",
    "              for l in range(filter.shape[0]):\n",
    "               sum=np.sum(np.multiply(new_inp_img[l,i:(filter.shape[1]+i),j:(filter.shape[2]+j)],filter[l]))\n",
    "               new_sum+=sum\n",
    "           #storing result in output array\n",
    "           if(i+filter.shape[1]<=new_inp_img.shape[1] and j+filter.shape[2]<=new_inp_img.shape[2]):\n",
    "              out[(k,int(i/s),int(j/s))]=new_sum\n",
    "    #generating activation map         \n",
    "    act_map=sigmoid(out)\n",
    "    return act_map\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART 2 : POOLING FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pooling functions that take activation map,kernel,stride,no. of filters as arguments\n",
    "def avg_pool(map,kernel_2,s,d):\n",
    "    #creating output array of required dimensions\n",
    "    output=np.empty((d,int(map.shape[1]/kernel_2.shape[1]),int(map.shape[2]/kernel_2.shape[2])))\n",
    "    \n",
    "    \n",
    "    for i in range(0,map.shape[1],s):#moving along height\n",
    "        for j in range(0,map.shape[2],s):#moving along width\n",
    "            if(i+kernel_2.shape[1]>map.shape[1] or j+kernel_2.shape[2]>map.shape[2]):\n",
    "                break\n",
    "            else: \n",
    "                #pooling the map\n",
    "                for k in range(d):\n",
    "                  sum_inp=np.sum(np.multiply(map[k,i:kernel_2.shape[1]+i,j:kernel_2.shape[2]+j],kernel_2[k]))\n",
    "            #storing result in the output array\n",
    "            if(i+kernel_2.shape[1]<=map.shape[1] and j+kernel_2.shape[2]<=map.shape[2]):\n",
    "                output[(k,int(i/s),int(j/s))]=float(sum_inp/(kernel_2.shape[1]*kernel_2.shape[2]))\n",
    "    return output\n",
    "                \n",
    "\n",
    "def max_pool(map,kernel_2,s,d):\n",
    "    output=np.empty((d,int(map.shape[1]/kernel_2.shape[1]),int(map.shape[2]/kernel_2.shape[2])))\n",
    "    \n",
    "    for i in range(0,map.shape[1],s):\n",
    "        for j in range(0,map.shape[2],s):\n",
    "            if(i+kernel_2.shape[1]>map.shape[1] or j+kernel_2.shape[2]>map.shape[2]):\n",
    "                break\n",
    "            else: \n",
    "                for k in range(d):\n",
    "                 sum_inp=np.max(np.multiply(map[k,i:(kernel_2.shape[1]+i),j:(kernel_2.shape[2]+j)],kernel_2[k]))\n",
    "            if(i+kernel_2.shape[1]<=map.shape[1] and j+kernel_2.shape[2]<=map.shape[2]):\n",
    "                output[(k,int(i/s),int(j/s))]=float(sum_inp)\n",
    "    return output\n",
    "\n",
    "def global_avg_pooling(input_vol):\n",
    "  out_vol=np.empty((1,input_vol.shape[0]))\n",
    "  for i in range(input_vol.shape[0]):\n",
    "    out_vol[(1,i)]=np.average(input_vol[i])\n",
    "  return out_vol\n",
    "    \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART 3: CONVOLUTION LAYER FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convolution layer function that takes image,no. of filters,kernel dimensions,stride, padding as arguments\n",
    "def convolution_layer(img,no_filter,ker_dim_1,ker_dim_2,ker_dim_3,strd,pad):\n",
    "    #creating a kernel of necessary dimensions\n",
    "    kernel=np.random.rand(ker_dim_1,ker_dim_2,ker_dim_3)\n",
    "    #calling the convolution function\n",
    "    return convolution_op(img,kernel,strd,pad,no_filter,sigmoid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART 4 : POOLING LAYER FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pooling layer function with activation map,stride,type of pooling function as arguments\n",
    "def pooling_layer(input_map,stride,avg_pool_fun:bool=True):\n",
    "  #creating kernel of necsarry dimensions\n",
    "    kernel=np.random.rand(input_map.shape[0],stride,stride)\n",
    "    #calling the pooling function\n",
    "    if avg_pool_fun==True:\n",
    "      return avg_pool(input_map,kernel,stride,3)\n",
    "    else:\n",
    "      return max_pool(input_map,kernel,stride,3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART 5 : FLATTEN FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten function that takes input volume ,specified output size as arguments\n",
    "def flatten(inp_volume,specified_size):\n",
    "    array=inp_volume\n",
    "    #total no. of elements in the input volume\n",
    "    res_dim=array.shape[0]*array.shape[1]*array.shape[2]\n",
    "    #reshaping the array\n",
    "    flat_array=array.reshape(1,res_dim)\n",
    "    #random weigth matrix for matrix multiplication giving out of size 1x(specified size)\n",
    "    weight_mat=np.random.rand(flat_array.shape[1],specified_size)\n",
    "    #matrix multiplication\n",
    "    result_matrix=np.matmul(flat_array,weight_mat)\n",
    "    return result_matrix\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART 6 : MLP FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP function that takes input vector. no. of hidden layers ,size of each hidden layer,no. of output nodes, boolean softmax functiion as arguments\n",
    "def MLP(inp_vector,no_hidden,size_hidden,out_size,sigmoid,softmax_fun:bool):\n",
    "    array=inp_vector\n",
    "    #creating random weight matrix for first step of forward pass between input vector and first hidden layer\n",
    "    wt_matrix=np.random.rand(inp_vector.shape[1],size_hidden)\n",
    "    #matrix multipliaction\n",
    "    first_out=np.matmul(array,wt_matrix)\n",
    "    first_res=sigmoid(first_out)\n",
    "    \n",
    "    #genearting weight matrices and carrying out forward pass between hidden layers \n",
    "    for i in range(no_hidden-1):\n",
    "        new_wt_matrix=np.random.rand(size_hidden,size_hidden)\n",
    "        res_mat=np.matmul(first_res,new_wt_matrix)\n",
    "        first_res=sigmoid(res_mat)\n",
    "     \n",
    "    #forward pass for last step   \n",
    "    final_wt_mat=np.random.rand(size_hidden,out_size)\n",
    "    final_out=np.matmul(first_res,final_wt_mat)  \n",
    "    final_res=sigmoid(final_out)\n",
    "    \n",
    "    #putting output in softmax function according to boolean value\n",
    "    if softmax_fun==True:\n",
    "       soft=softmax(final_res)\n",
    "       return soft\n",
    "    else:\n",
    "      return(final_res)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART 7 : FEED FORWARD PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feed forward path that takes input image and output dimensions as arguments\n",
    "def feed_forward(input,output_dim,bottleneck:bool=True):\n",
    "  res_1=convolution_layer(input,16,input.shape[0],3,3,1,1)#calling convolution layer function\n",
    "  res_2=pooling_layer(res_1,2,False)#calling pooling layer function\n",
    "  res_3=convolution_layer(res_2,8,res_2.shape[0],3,3,2,1)#again convolution layer function\n",
    "  res_4=pooling_layer(res_3,2,False)#agian pooling layer function\n",
    "  res_5=flatten(res_4,10)# flatten function\n",
    "  if (bottleneck):\n",
    "    bottleneck_layer=res_5\n",
    "    return MLP(res_5,1,10,output_dim,sigmoid,softmax_fun=True),bottleneck_layer#bottlneck,MLP(res_5,1,10,output_dim,softmax_fun=True)#\n",
    "  return MLP(res_5,1,10,output_dim,sigmoid,softmax_fun=True)#returning the MLP output\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DOWNLOADING THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset=datasets.CIFAR10(root='./data',train=False,download=True,transform=transforms.ToTensor())\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " IMPLEMENTING FEED FORWARD PATH FOR AN IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1216,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5539/2296116046.py:1: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  dataset=np.array(dataset)\n",
      "/tmp/ipykernel_5539/2296116046.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  dataset=np.array(dataset)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output vector =  [[0.09936655 0.10064495 0.09909822 0.10036792 0.10053505 0.10055357\n",
      "  0.09974195 0.09930156 0.09984056 0.10054966]]\n"
     ]
    }
   ],
   "source": [
    "dataset=np.array(dataset)\n",
    "output=feed_forward(input=dataset[1][0],output_dim=10,bottleneck=False)\n",
    "print(\"output vector = \",output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART 8a : FEEDFORWARD PATH FOR SINGLE IMAGE BELONGING TO EVERY LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output vector for label 1 -\n",
      " (array([[0.10009885, 0.10050199, 0.1004218 , 0.10026083, 0.09876198,\n",
      "        0.10050321, 0.09900182, 0.10024808, 0.10016705, 0.10003439]]), array([[4.18994821, 4.39779774, 5.00306539, 4.57060876, 3.13259948,\n",
      "        4.60561489, 4.12731853, 4.7350865 , 3.74108539, 4.92964591]]))\n",
      "output vector for label 2 -\n",
      " (array([[0.10034507, 0.10044161, 0.09946499, 0.10033211, 0.10039185,\n",
      "        0.09981876, 0.09987481, 0.10034803, 0.09890052, 0.10008225]]), array([[6.1498718 , 6.57345156, 5.10655265, 5.51037423, 5.4354885 ,\n",
      "        6.66411321, 5.99130322, 5.85661389, 4.14195689, 5.39476567]]))\n",
      "output vector for label 3 -\n",
      " (array([[0.10043719, 0.09793961, 0.10042322, 0.09703861, 0.10095696,\n",
      "        0.10082321, 0.10072295, 0.10074175, 0.1005342 , 0.10038231]]), array([[7.59838795, 6.80332206, 5.95289404, 6.76737876, 7.04857605,\n",
      "        4.66144056, 5.52730595, 6.4781673 , 7.57709685, 6.43728652]]))\n",
      "output vector for label 4 -\n",
      " (array([[0.10022665, 0.10035883, 0.10032653, 0.10067064, 0.09893849,\n",
      "        0.10006984, 0.09949789, 0.10038335, 0.10021373, 0.09931404]]), array([[7.09114149, 6.8945039 , 6.89282895, 5.6151806 , 4.94939746,\n",
      "        5.88531418, 7.33968243, 7.82008094, 6.30509116, 6.6643197 ]]))\n",
      "output vector for label 5 -\n",
      " (array([[0.10053413, 0.10035828, 0.09993357, 0.10040577, 0.09853544,\n",
      "        0.09977442, 0.10037251, 0.10032209, 0.09964053, 0.10012327]]), array([[6.51364132, 6.09261462, 7.35760789, 6.52909779, 7.48935898,\n",
      "        7.92069824, 8.58917396, 7.75408944, 8.12284067, 5.9950117 ]]))\n",
      "output vector for label 6 -\n",
      " (array([[0.10092216, 0.10084068, 0.10035273, 0.10068618, 0.10066871,\n",
      "        0.0991631 , 0.09694696, 0.10047902, 0.10064764, 0.09929282]]), array([[4.5790942 , 4.66170099, 4.98302081, 3.59707619, 3.7399676 ,\n",
      "        3.31758056, 3.87009683, 4.16217349, 4.34183995, 3.68186298]]))\n",
      "output vector for label 7 -\n",
      " (array([[0.09939891, 0.10047543, 0.10053351, 0.09982666, 0.10060219,\n",
      "        0.10024481, 0.09945324, 0.10013782, 0.09899522, 0.10033221]]), array([[4.66150826, 6.94132918, 6.45759866, 7.14893519, 7.77572652,\n",
      "        6.11467825, 7.85681163, 7.61695627, 6.92859846, 5.71485433]]))\n",
      "output vector for label 8 -\n",
      " (array([[0.10020152, 0.10044852, 0.10016716, 0.10004922, 0.100203  ,\n",
      "        0.10053555, 0.09926246, 0.09845592, 0.1006327 , 0.10004394]]), array([[7.30622394, 6.75527594, 6.27939675, 4.98048989, 5.88812285,\n",
      "        5.76693228, 6.97821024, 6.40668482, 7.0742154 , 6.01461703]]))\n",
      "output vector for label 9 -\n",
      " (array([[0.1003731 , 0.10041716, 0.10049093, 0.10030677, 0.0996361 ,\n",
      "        0.09969994, 0.09824804, 0.10017501, 0.1008528 , 0.09980015]]), array([[1.82394319, 2.16576661, 2.10091115, 2.76475011, 3.16621008,\n",
      "        2.72936413, 2.56458748, 2.28928683, 2.77983339, 2.31177023]]))\n",
      "output vector for label 10 -\n",
      " (array([[0.10091394, 0.09984581, 0.10062184, 0.09994913, 0.09944976,\n",
      "        0.10006508, 0.10091294, 0.09759609, 0.10058732, 0.1000581 ]]), array([[8.0647682 , 6.8015642 , 6.04431661, 6.63545446, 5.85652252,\n",
      "        7.73295478, 6.53656542, 7.68703706, 7.01834374, 6.68843572]]))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(10):\n",
    "    input_dat=dataset[dataset[:,1]==i][0]\n",
    "    output=feed_forward(input=input_dat[0],output_dim=10)\n",
    "    print(f\"output vector for label {i+1} -\\n\",output)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART 8b : BOTTLENECK LAYER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1218,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. PCA expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1218], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m new_data\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39marray(new_data)\n\u001b[1;32m     11\u001b[0m PCA_return\u001b[39m=\u001b[39mPCA(n_components\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m new_data\u001b[39m=\u001b[39mPCA_return\u001b[39m.\u001b[39;49mfit_transform(new_data)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 142\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    143\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    144\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    145\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    147\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    148\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/decomposition/_pca.py:462\u001b[0m, in \u001b[0;36mPCA.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[39m\"\"\"Fit the model with X and apply the dimensionality reduction on X.\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \n\u001b[1;32m    441\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[39mC-ordered array, use 'np.ascontiguousarray'.\u001b[39;00m\n\u001b[1;32m    459\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    460\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m--> 462\u001b[0m U, S, Vt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X)\n\u001b[1;32m    463\u001b[0m U \u001b[39m=\u001b[39m U[:, : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_components_]\n\u001b[1;32m    465\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwhiten:\n\u001b[1;32m    466\u001b[0m     \u001b[39m# X_new = X * V / S * sqrt(n_samples) = U * sqrt(n_samples)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/decomposition/_pca.py:485\u001b[0m, in \u001b[0;36mPCA._fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[39mif\u001b[39;00m issparse(X):\n\u001b[1;32m    480\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPCA does not support sparse input. See \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    482\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTruncatedSVD for a possible alternative.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    483\u001b[0m     )\n\u001b[0;32m--> 485\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    486\u001b[0m     X, dtype\u001b[39m=\u001b[39;49m[np\u001b[39m.\u001b[39;49mfloat64, np\u001b[39m.\u001b[39;49mfloat32], ensure_2d\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy\n\u001b[1;32m    487\u001b[0m )\n\u001b[1;32m    489\u001b[0m \u001b[39m# Handle n_components==None\u001b[39;00m\n\u001b[1;32m    490\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_components \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:546\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    545\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 546\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    547\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[1;32m    548\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:915\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    911\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    912\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    913\u001b[0m     )\n\u001b[1;32m    914\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nd \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[0;32m--> 915\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    916\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    917\u001b[0m         \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    918\u001b[0m     )\n\u001b[1;32m    920\u001b[0m \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[1;32m    921\u001b[0m     _assert_all_finite(\n\u001b[1;32m    922\u001b[0m         array,\n\u001b[1;32m    923\u001b[0m         input_name\u001b[39m=\u001b[39minput_name,\n\u001b[1;32m    924\u001b[0m         estimator_name\u001b[39m=\u001b[39mestimator_name,\n\u001b[1;32m    925\u001b[0m         allow_nan\u001b[39m=\u001b[39mforce_all_finite \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mallow-nan\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    926\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with dim 3. PCA expected <= 2."
     ]
    }
   ],
   "source": [
    "new_data=[]\n",
    "\n",
    "for i in range(10):\n",
    "    new_inp=dataset[dataset[:,1]==i][:3]\n",
    "    \n",
    "    for j in range(3):\n",
    "        new_out,bottleneck_layer=feed_forward(input=new_inp[j][0],output_dim=10,bottleneck=True)\n",
    "        bottleneck_layer=np.array(bottleneck_layer)\n",
    "        new_data.append(bottleneck_layer)\n",
    "new_data=np.array(new_data)\n",
    "PCA_return=PCA(n_components=2)\n",
    "new_data=PCA_return.fit_transform(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(new_data[:,0],new_data[:,1],'ro')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
